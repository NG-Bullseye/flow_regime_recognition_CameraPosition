{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 16:32:58.673899: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "p = os.path.abspath('.')\n",
    "sys.path.insert(1, p)\n",
    "from models.lenet5Autoencode import LeNet\n",
    "from data_import_and_preprocessing.dataset_formation import DataParser, ImageDataExtractor, LabelExtractor, \\\n",
    "    DataSetCreator\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"initialize Dataset and training params from params.yml\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition/inference\n",
      "/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 16:33:04.330534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-29 16:33:04.936934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:18:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition')\n",
    "print(os.getcwd())\n",
    "with open('params.yaml', 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    no_epochs = params['training']['no_epochs']\n",
    "    batch_size = params['training']['batch_size']\n",
    "    loss = params['training']['loss']\n",
    "    picture_width = params['preprocessing']['picture_width']\n",
    "    picture_hight = params['preprocessing']['picture_hight']\n",
    "    no_classes = params['preprocessing']['no_classes']\n",
    "\n",
    "    data_dir = 'data/preprocessed'\n",
    "    data_parser = DataParser(data_dir)\n",
    "    image_data_extractor = ImageDataExtractor((picture_width, picture_hight, 1))\n",
    "    label_extractor = LabelExtractor(no_classes=no_classes) #anzahl der classen\n",
    "    dataset = DataSetCreator(data_parser, image_data_extractor, label_extractor, no_repeats=no_epochs)\n",
    "    no_points = len(dataset)\n",
    "    no_points_train = int(no_points * 0.8)\n",
    "    no_points_val = int(no_points * 0.1)\n",
    "\n",
    "    dataset_train = dataset.take(no_points=no_points_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 16:33:15.126145: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.10MiB (rounded to 6400000)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-06-29 16:33:15.126212: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-06-29 16:33:15.126237: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 12, Chunks in use: 12. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 356B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126256: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126272: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126288: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 2, Chunks in use: 1. 4.8KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126301: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126314: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126327: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126340: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126359: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 97.8KiB allocated for chunks. 97.8KiB in use in bin. 97.7KiB client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126375: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 195.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126388: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126400: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126414: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.70MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126427: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126440: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126457: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 16.00MiB allocated for chunks. 16.00MiB in use in bin. 12.21MiB client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126471: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126483: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126496: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126513: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126525: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-06-29 16:33:15.126540: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 6.10MiB was 4.00MiB, Chunk State: \n",
      "2022-06-29 16:33:15.126552: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 2097152\n",
      "2022-06-29 16:33:15.126573: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400000 of size 256 next 1\n",
      "2022-06-29 16:33:15.126584: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400100 of size 1280 next 2\n",
      "2022-06-29 16:33:15.126596: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400600 of size 256 next 3\n",
      "2022-06-29 16:33:15.126607: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400700 of size 256 next 4\n",
      "2022-06-29 16:33:15.126617: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400800 of size 256 next 5\n",
      "2022-06-29 16:33:15.126627: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400900 of size 256 next 6\n",
      "2022-06-29 16:33:15.126637: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400a00 of size 256 next 7\n",
      "2022-06-29 16:33:15.126647: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400b00 of size 256 next 8\n",
      "2022-06-29 16:33:15.126657: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400c00 of size 256 next 9\n",
      "2022-06-29 16:33:15.126667: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400d00 of size 256 next 12\n",
      "2022-06-29 16:33:15.126677: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400e00 of size 256 next 13\n",
      "2022-06-29 16:33:15.126687: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6400f00 of size 256 next 16\n",
      "2022-06-29 16:33:15.126697: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6401000 of size 256 next 17\n",
      "2022-06-29 16:33:15.126707: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f8fc6401100 of size 2816 next 10\n",
      "2022-06-29 16:33:15.126718: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6401c00 of size 2048 next 11\n",
      "2022-06-29 16:33:15.126728: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f8fc6402400 of size 200192 next 15\n",
      "2022-06-29 16:33:15.126739: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6433200 of size 100096 next 14\n",
      "2022-06-29 16:33:15.126750: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f8fc644b900 of size 1787648 next 18446744073709551615\n",
      "2022-06-29 16:33:15.126760: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 8388608\n",
      "2022-06-29 16:33:15.126771: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6600000 of size 8388608 next 18446744073709551615\n",
      "2022-06-29 16:33:15.126781: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 8388608\n",
      "2022-06-29 16:33:15.126792: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f8fc6e00000 of size 8388608 next 18446744073709551615\n",
      "2022-06-29 16:33:15.126802: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-06-29 16:33:15.126816: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 12 Chunks of size 256 totalling 3.0KiB\n",
      "2022-06-29 16:33:15.126829: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-06-29 16:33:15.126841: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2048 totalling 2.0KiB\n",
      "2022-06-29 16:33:15.126856: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 100096 totalling 97.8KiB\n",
      "2022-06-29 16:33:15.126870: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 8388608 totalling 16.00MiB\n",
      "2022-06-29 16:33:15.126883: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 16.10MiB\n",
      "2022-06-29 16:33:15.126895: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 18874368 memory_limit_: 20250624 available bytes: 1376256 curr_region_allocation_bytes_: 16777216\n",
      "2022-06-29 16:33:15.126915: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                        20250624\n",
      "InUse:                        16883712\n",
      "MaxInUse:                     16883968\n",
      "NumAllocs:                          25\n",
      "MaxAllocSize:                  8388608\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-06-29 16:33:15.126933: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **_________***********************************xxxxxxxxx***********************************xxxxxxxxxx\n",
      "2022-06-29 16:33:15.126998: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2485231/3584877080.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition/training/model/trained_model.h5\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreconstructed_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/mnt/0A60B2CB60B2BD2F/interpreters/Python-3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/0A60B2CB60B2BD2F/interpreters/Python-3.9/lib/python3.9/site-packages/keras/backend.py\u001B[0m in \u001B[0;36mrandom_uniform\u001B[0;34m(self, shape, minval, maxval, dtype)\u001B[0m\n\u001B[1;32m   1918\u001B[0m       return self._generator.uniform(\n\u001B[1;32m   1919\u001B[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001B[0;32m-> 1920\u001B[0;31m     return tf.random.uniform(\n\u001B[0m\u001B[1;32m   1921\u001B[0m         \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mminval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mminval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaxval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1922\u001B[0m         seed=self.make_legacy_seed())\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "model_path = \"/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition/training/model/trained_model.h5\"\n",
    "reconstructed_model = tf.keras.models.load_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load img and infer class label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = '/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition/data/preprocessed/1100000001.png'\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "img_preprocessed  = img / 255\n",
    "\n",
    "x = np.expand_dims(img_preprocessed, axis=0)\n",
    "\n",
    "\n",
    "preds = reconstructed_model.predict(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pretty the prediction for console output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred=np.around(preds,3)\n",
    "inferedClass=\"\"\n",
    "\n",
    "prediction= pred[0]\n",
    "inferedAccuracyFlooded=prediction[0]\n",
    "inferedAccuracyLoaded=prediction[1]\n",
    "inferedAccuracyDispersed=prediction[2]\n",
    "\n",
    "classaccuracy = max(inferedAccuracyFlooded,inferedAccuracyDispersed,inferedAccuracyLoaded)\n",
    "if classaccuracy == inferedAccuracyFlooded:\n",
    "    inferedClass= \"Flooded\"\n",
    "elif classaccuracy == inferedAccuracyLoaded:\n",
    "    inferedClass= \"Loaded\"\n",
    "elif classaccuracy == inferedAccuracyDispersed:\n",
    "    inferedClass= \"Despersed\"\n",
    "print(inferedClass+\": \"+str(classaccuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get dense autoencode auxilary putput"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reconstructed_model.layers[11].output\n",
    "autoencodeLayer = K.function([reconstructed_model.layers[0].input], [reconstructed_model.layers[11].output])\n",
    "autoencodeLayer_output = autoencodeLayer(x)[0]\n",
    "autoencodeLayer_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## asign Points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data_import_and_preprocessing.dataset_formation import DataParser, ImageDataExtractor, LabelExtractor, \\\n",
    "    DataSetCreator\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/mnt/0A60B2CB60B2BD2F/Projects/leo_flow_regime_recognition')\n",
    "print(os.getcwd())\n",
    "with open('params.yaml', 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "no_epochs = params['training']['no_epochs']\n",
    "batch_size = params['training']['batch_size']\n",
    "picture_width = params['preprocessing']['picture_width']\n",
    "picture_hight = params['preprocessing']['picture_hight']\n",
    "no_classes = params['preprocessing']['no_classes']\n",
    "\n",
    "data_dir = 'data/preprocessed'\n",
    "data_parser = DataParser(data_dir)\n",
    "image_data_extractor = ImageDataExtractor((picture_width, picture_hight, 1))\n",
    "label_extractor = LabelExtractor(no_classes=no_classes) #anzahl der classen\n",
    "dataset = DataSetCreator(data_parser, image_data_extractor, label_extractor, no_repeats=no_epochs)\n",
    "pathList = []\n",
    "for imagePath in dataset.data_points:\n",
    "    pathList.append(imagePath.path_to_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.lenet5Autoencode import LeNet\n",
    "import pandas as pd\n",
    "#Create a clustering model\n",
    "partialDataNo=100\n",
    "points_n = len(pathList)/partialDataNo\n",
    "clusters_n = 3\n",
    "iteration_n = 100\n",
    "i=0\n",
    "model = LeNet\n",
    "\n",
    "listOfAuxValues = []\n",
    "valueLabelMapping = pd.DataFrame(columns=[\"point\", \"label\"])\n",
    "\n",
    "\n",
    "skippCounter=0\n",
    "for path in pathList:\n",
    "    skippCounter=skippCounter+1\n",
    "    if  skippCounter%partialDataNo!=0:\n",
    "        continue\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "    img_preprocessed  = img / 255\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    reconstructed_model.predict(x)\n",
    "    autoencodeLayer = K.function([reconstructed_model.layers[0].input], [reconstructed_model.layers[11].output])\n",
    "    autoencodeLayer_output = autoencodeLayer(x)[0]\n",
    "    listOfAuxValues.append(autoencodeLayer_output)\n",
    "\n",
    "    pred=np.around(preds,3)\n",
    "    inferedClass=\"\"\n",
    "\n",
    "    prediction= pred[0]\n",
    "    inferedAccuracyFlooded=prediction[0]\n",
    "    inferedAccuracyLoaded=prediction[1]\n",
    "    inferedAccuracyDispersed=prediction[2]\n",
    "\n",
    "    classaccuracy = max(inferedAccuracyFlooded,inferedAccuracyDispersed,inferedAccuracyLoaded)\n",
    "    if classaccuracy == inferedAccuracyFlooded:\n",
    "        inferedClass= \"Flooded\"\n",
    "    elif classaccuracy == inferedAccuracyLoaded:\n",
    "        inferedClass= \"Loaded\"\n",
    "    elif classaccuracy == inferedAccuracyDispersed:\n",
    "        inferedClass= \"Despersed\"\n",
    "    print(inferedClass+\": \"+str(classaccuracy))\n",
    "    entry = pd.DataFrame.from_dict({\n",
    "    \"point\": [autoencodeLayer_output],\n",
    "    \"label\":  [inferedClass+\": \"+str(classaccuracy)]\n",
    "    })\n",
    "    valueLabelMapping = pd.concat([valueLabelMapping, entry], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## init clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe = []\n",
    "for p in listOfAuxValues:\n",
    "    print(p[0])\n",
    "    dataframe.append(p[0])\n",
    "\n",
    "points = tf.convert_to_tensor(dataframe)\n",
    "points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "centroids = tf.Variable(tf.slice(tf.random.shuffle(points), [0, 0], [clusters_n, -1]))\n",
    "\n",
    "points_expanded = tf.expand_dims(points, 0)\n",
    "centroids_expanded = tf.expand_dims(centroids, 1)\n",
    "\n",
    "distances = tf.reduce_sum(tf.square(tf.subtract(points_expanded, centroids_expanded)), 2)\n",
    "assignments = tf.argmin(distances, 0)\n",
    "\n",
    "means = []\n",
    "for c in range(clusters_n):\n",
    "    means.append(tf.reduce_mean(\n",
    "      tf.gather(points,\n",
    "                tf.reshape(\n",
    "                  tf.where(\n",
    "                    tf.equal(assignments, c)\n",
    "                  ),[1,-1])\n",
    "               ),[1]))\n",
    "\n",
    "new_centroids = tf.concat(means, 0)\n",
    "\n",
    "update_centroids =  tf.compat.v1.assign(centroids, new_centroids)\n",
    "init = tf.compat.v1.global_variables_initializer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for step in range(iteration_n):\n",
    "    [_, centroid_values, points_values, assignment_values] = [update_centroids, centroids, points, assignments]\n",
    "\n",
    "    print(\"centroids\", centroid_values)\n",
    "\n",
    "plt.scatter(points_values[:, 0], points_values[:, 1], c=assignment_values, s=50, alpha=0.5)\n",
    "plt.plot(centroid_values[:, 0], centroid_values[:, 1], 'kx', markersize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valueLabelMapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}